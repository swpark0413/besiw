% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/eigenGSIW.R
\name{eigenGSIW}
\alias{eigenGSIW}
\title{Bayesian estimation of eigenstructure in spiked covariance models using the gSIW prior}
\usage{
eigenGSIW(
  X,
  k,
  a_vec = NULL,
  H = NULL,
  nmcmc = 1e+05,
  nburn = floor(nmcmc/2),
  nthin = 100,
  progress = TRUE
)
}
\arguments{
\item{X}{A \eqn{n \times p} data matrix.}

\item{k}{An integer specifying the number of spiked eigenvalues.}

\item{a_vec}{A numeric vector of length \eqn{p}, specifying prior hyperparameters for the generalized inverse-Wishart prior, which controls the shrinkage behavior of the eigenvalues.}

\item{H}{A \eqn{p \times p} positive definite matrix used in the prior specification.}

\item{nmcmc}{The total number of MCMC iterations.}

\item{nburn}{The number of burn-in iterations to discard.}

\item{nthin}{The thinning interval for storing posterior samples.}

\item{progress}{Logical. Whether to display progress updates during sampling.}
}
\value{
A list of class \code{"besiw"} containing:
\describe{
  \item{\code{Lambda}}{A list of posterior samples of eigenvalues (length: number of retained iterations).}
  \item{\code{Gamma}}{A list of posterior samples of eigenvector matrices.}
  \item{\code{k}}{The number of spiked eigenvalues used.}
}
}
\description{
Provides posterior samples of eigenvalues and eigenvectors from a spiked covariance matrix using a generalized shrinkage inverse-Wishart (gSIW) prior. 
The method supports Bayesian estimation of the eigenstructure in high-dimensional settings.
}
\details{
Kim, Lee, Park, and Lee (2025+) proposed a spiked covariance model using a generalized shrinkage inverse-Wishart (gSIW) prior for estimating the spiked eigenstructure of a covariance matrix,
focusing on the top \eqn{k} eigenvalues and eigenvectors. The generalized Shrinkage inverse-Wishart (gSIW) prior whose density is defined as 
whose density is defined as
\deqn{\pi^{gSIW}(\Lambda, \mathrm{U} |a_1,\ldots,a_p,b,H) (d\Lambda) (d\mathrm{U}) \propto   
\dfrac{etr(-\dfrac{1}{2}\mathrm{U}\Lambda^{-1} \mathrm{U}^T H)}{\prod\limits_{i=1}^p\lambda_i^{a_i}\prod\limits_{i<j}|\lambda_i-\lambda_j|^{b-1}}(d\Lambda) (d\mathrm{U})}
where \eqn{a_1,\ldots,a_p>0}, \eqn{b\in[0,1]}, \eqn{H \in \mathcal{C}_p :=\{ A \in \mathbb{R}^{p\times p}: A \text{ is positive definite} \}}, \eqn{\lambda_1,\cdots,\lambda_p} are the unordered eigenvalues, and \eqn{\mathrm{U}} is the eigenvector matrix of \eqn{\Sigma}.
By allowing each \eqn{a_i} to be defined differently for each \eqn{\lambda_i}, we can consider a prior distribution that is more general than the SIW prior (Berger et al., 2020)  to address some of the limitations of the inverse Wishart prior.
Unlike the SIW prior, the gSIW prior explicitly distinguishes between the spiked and non-spiked components, leading to improved posterior performance.
For simplicity and computational efficiency, we assume \eqn{b=1} throughout this package. 


We consider the spectral decomposition of \eqn{nS = QWQ^T}, 
where \eqn{W = \mathrm{diag}(n\hat{\lambda}_1, \ldots, n\hat{\lambda}_{n \wedge p}, 0, \ldots, 0)} 
and \eqn{Q} is a \eqn{p \times p} orthogonal matrix whose \eqn{i}th column is the eigenvector corresponding to the \eqn{i}th eigenvalue. 
We define \eqn{\Gamma = Q^T \mathrm{U}} as the rotated eigenvector matrix under the sample eigenspace.
Given a generalized shrinkage inverse-Wishart (gSIW) prior, which is conjugate to the multivariate normal distribution,
the posterior density is given by
\deqn{ \pi(\Lambda,\Gamma\vert \mathbb{X}_n)\propto \prod\limits_{i=1}^p \lambda_i^{-a_i - n/2} \, \mathrm{etr}\left(-\dfrac{1}{2}\Lambda^{-1}\Gamma^T(hI_p + W)\Gamma\right),}
where \eqn{\mathbb{X}_n} denotes the \eqn{n} observations and \eqn{h > 0} is a positive constant.
The gibbs sampling algorithm for generating posterior samples from \eqn{[\Lambda\vert \Gamma, \mathbb{X}_n]} and \eqn{[\Gamma\vert \Lambda, \mathbb{X}_n]} is given below:
\itemize{
\item  Independently generate \eqn{\lambda_i \sim \text{Inverse-Gamma}(a_i+n/2-1,c_i/2)}. Here, \eqn{c_i} is the \eqn{(i,i)} element of \eqn{\Gamma^T(hI_p+W)\Gamma}.

\item simulate \eqn{\Gamma} from \eqn{\pi(\Gamma\vert \Lambda,\mathbb{X}_n)\propto etr(-\dfrac{1}{2}\Lambda^{-1}\Gamma^T(hI_p+W)\Gamma)}.

}
For more details, see Kim, Lee, Park, and Lee (2025+).
}
\examples{

\dontrun{

# generate a spiked covariance matrix:
n <- 50
p <- 100
K <- 3
leading <- c(50,20,10)
remaining <- rep(1, p - K)
Sigma0 <- diag(c(leading, remaining), p)

# generate data
set.seed(413)
X <- MASS::mvrnorm(n = n, mu = rep(0, p), Sigma = Sigma0)

# Run a MCMC algorithm using a generalized shrinkage inverse-Wishart (gSIW) prior 
# for estimating eigenvalues and eigenvectors of a covariance matrix. 
H <- 4 * diag(rep(1, p))
iter <- 100000
burnin <- floor(iter / 2)
thin <- 100
res <- besiw::eigenGSIW(X = X, k = K, H = H, nmcmc = iter, nburn = burnin, nthin = thin)
}

}
\references{
Kim, S., Lee, K., Park, S., and Lee, J. (2025+), "Eigenstructure inference for high-dimensional covariance with shrinkage inverse-Wishart prior",
	\emph{Arxiv}, URL: \url{https://arxiv.org/abs/2412.10753}.
	
Berger, J. O., Sun, D., and Song, C. (2020), "Bayesian analysis of the covariance matrix of a multivariate normal distribution with a new class of priors",
	\emph{The Annals of Statistics}, 48(4), 2381â€“2403.
}
\seealso{
\code{estimate}
}
\author{
Sewon Park
}
\keyword{covariance}
\keyword{eigenvalue}
\keyword{eigenvector}
\keyword{spiked}
